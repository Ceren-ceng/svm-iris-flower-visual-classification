# ğŸŒ¸ SVM ile Iris Ã‡iÃ§ek TÃ¼rÃ¼ SÄ±nÄ±flandÄ±rma ve GÃ¶rselleÅŸtirme

  Bu projede, **Support Vector Machine (SVM)** algoritmasÄ±nÄ±n makine Ã¶ÄŸrenmesinde tam olarak **ne iÅŸe yaradÄ±ÄŸÄ±nÄ±**, parametrelerinin (kernel, C, gamma, degree, margin) pratikte ne fark yarattÄ±ÄŸÄ±nÄ± ve Iris veri setinde nasÄ±l kullanÄ±ldÄ±ÄŸÄ±nÄ± hem kod hem de Ã§Ä±ktÄ±lar ve grafiklerle gÃ¶sterilmiÅŸti.

  ---

  ## 1ï¸âƒ£ SVM (Support Vector Machine) Nedir? ğŸ§ 

  - SVM, en iyi ayrÄ±m sÄ±nÄ±rÄ±nÄ± (hiperdÃ¼zlem) bulmaya Ã§alÄ±ÅŸan bir algoritmadÄ±r.
  - KomÅŸulara bakarak deÄŸil, tÃ¼m veri kÃ¼mesinin geometrisini dikkate alÄ±r.
  - SÄ±nÄ±r, iki sÄ±nÄ±fÄ± ayÄ±ran â€œen geniÅŸ marjlÄ± Ã§izgidir.
  - Ã‡oklu sÄ±nÄ±flar iÃ§in â€œone-vs-restâ€ tekniÄŸiyle otomatik uyarlanÄ±r.
  - ğŸ” Ne demek? 
    Her Ã§iÃ§ek tÃ¼rÃ¼nÃ¼ mÃ¼mkÃ¼n olan en â€œkeskinâ€ ÅŸekilde ayÄ±rÄ±r. Ezberci deÄŸil, gerÃ§ekten genelleyen bir modeldir.

  ---

  ## 2ï¸âƒ£ SVM Parametreleri ve KavramlarÄ±

  - Kernel SeÃ§imiğŸŒ€  
    - `linear` â¡ï¸ DÃ¼z Ã§izgiyle ayÄ±rma (en sade, doÄŸrudan)
    - `poly` â¿ Polinom eÄŸriyle ayÄ±rma (karmaÅŸÄ±klÄ±k ekler)
    - `rbf` ğŸ¥¨ Dairesel/dalgalÄ± sÄ±nÄ±rlar (karmaÅŸÄ±k yapÄ±)
    - ğŸ” KullanÄ±mÄ±:  
      KarmaÅŸÄ±k veri iÃ§in `rbf` veya `poly`, basit ayrÄ±labilen veri iÃ§in `linear`.

  - C (Ceza KatsayÄ±sÄ±) âš–ï¸  
    - BÃ¼yÃ¼k C â†’ Sert sÄ±nÄ±r (hata kabul etmez, aÅŸÄ±rÄ± Ã¶ÄŸrenir)
    - KÃ¼Ã§Ã¼k C â†’ Esnek sÄ±nÄ±r (bazÄ± hatalarÄ± tolere eder, genellemeye aÃ§Ä±k)
    - ğŸ” **Taktik:**  
      Overfitting riskinde Câ€™yi kÃ¼Ã§Ã¼lt, veri Ã§ok net ayrÄ±lÄ±yorsa bÃ¼yÃ¼tebilirsin.

  - Gamma ğŸ”¬  
    - DÃ¼ÅŸÃ¼k gamma: SÄ±nÄ±r daha dÃ¼z, uzak noktalar dikkate alÄ±nÄ±r.
    - YÃ¼ksek gamma: SÄ±nÄ±r Ã§ok kÄ±vrÄ±mlÄ±, sadece yakÄ±n noktalar etkili.
    - Sadece `rbf` ve `poly` kernelde etkili.

  - Degree 2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£  
    - Polinomun derecesi. Sadece `poly` kernelde Ã¶nemli.

  - Soft/Hard Margin 
    - Soft margin â¡ï¸ GerÃ§ek veriyle uyumlu, pratikte en Ã§ok kullanÄ±lan.
    - Hard margin â¡ï¸ Teoride sÄ±fÄ±r hata, ama gÃ¼rÃ¼ltÃ¼lÃ¼ veride anlamlÄ± deÄŸil.

  ---

  ## 3ï¸âƒ£ Veri HazÄ±rlÄ±ÄŸÄ±, EÄŸitim ve Test AyrÄ±mÄ±

  - Her tÃ¼rden eÅŸit miktarda test verisi ayÄ±rmak, modelin tÃ¼m sÄ±nÄ±flarÄ± adilce Ã¶ÄŸrenmesini saÄŸlar.
  - EÄŸitim seti: Modelin gÃ¶rdÃ¼ÄŸÃ¼, Ã¶ÄŸrendiÄŸi veriler  
    Test seti: Modelin hiÃ§ gÃ¶rmediÄŸi, gerÃ§ekten tahmin yapmak zorunda olduÄŸu veriler  
  - ğŸ” Neden Ã¶nemli? 
    Sadece eÄŸitim setinde yÃ¼ksek doÄŸruluk "ezber" olabilir. GerÃ§ek baÅŸarÄ± test setinde Ã¶lÃ§Ã¼lÃ¼r.
    kernel, C, gamma gibi parametreleri deÄŸiÅŸtirerek Ã§Ä±ktÄ±da farklÄ± sÄ±nÄ±rlara ve baÅŸarÄ± oranlarÄ±na ulaÅŸabilirsin.

ğŸ” GÃ¶zlem:
Linear kernel ile veri net ayrÄ±lÄ±yorsa, doÄŸruluk %100 olur. KarmaÅŸÄ±k veri iÃ§in rbf veya polinom deneyebilirsin.

Ã‡IKTILARIN YORUMLANMASI:
Precision ğŸ¯: Modelin tahminlerinin ne kadar isabetli olduÄŸunu gÃ¶sterir.

Recall ğŸ”: Modelin gerÃ§ek deÄŸerleri ne kadar bulduÄŸunu Ã¶lÃ§er.

f1-score ğŸ†: Precision ve recall'un dengesi.

Support ğŸ‘¥: O sÄ±nÄ±ftaki test Ã¶rneÄŸi sayÄ±sÄ±.


PCA ile 2 Boyuta Ä°ndir ve Karar SÄ±nÄ±rÄ± Ã‡iz
PCA, 4 boyutlu veri uzayÄ±nÄ± 2 boyuta indirger ve modeli gÃ¶rsel olarak anlaÅŸÄ±lÄ±r kÄ±lar.

SVMâ€™in karar sÄ±nÄ±rlarÄ±, eÄŸitim ve test verilerinin daÄŸÄ±lÄ±mÄ± net olarak gÃ¶rÃ¼lebilir.

Grafikte:

KÄ±rmÄ±zÄ±/YeÅŸil/Mavi noktalar: 3 farklÄ± tÃ¼rÃ¼n eÄŸitim Ã¶rnekleri

X iÅŸaretleri: Test Ã¶rnekleri

â­ Siyah yÄ±ldÄ±z: Yeni tahmin edilen Ã§iÃ§ek (yeni bir giriÅŸ)

AÃ§Ä±k renkli bÃ¶lgeler: Modelin karar sÄ±nÄ±rÄ± (hangi alan hangi tÃ¼r?)

ğŸ” Sezgisel Yorum:
EÄŸer yÄ±ldÄ±z â€œkÄ±rmÄ±zÄ±â€ bÃ¶lgeye dÃ¼ÅŸerse model onu o tÃ¼r olarak sÄ±nÄ±flandÄ±rÄ±r.
SÄ±nÄ±rÄ±n karmaÅŸÄ±klÄ±ÄŸÄ± kernel/gamma/C ile deÄŸiÅŸir.

7ï¸âƒ£ FarklÄ± Kernel ve Parametrelerin Etkisi
kernel='linear': Net Ã§izgi, veriler net ayrÄ±lÄ±yorsa harika.

kernel='rbf', gamma=5: SÄ±nÄ±r Ã§ok kÄ±vrÄ±lÄ±r, modelin karmaÅŸÄ±klÄ±ÄŸÄ± artar, overfitting olabilir.

kernel='poly', degree=3: SÄ±nÄ±r parabol veya kÃ¼bik eÄŸri olur.

C Ã§ok bÃ¼yÃ¼kse: Model hata yapmaz ama testte dÃ¼ÅŸÃ¼k baÅŸarÄ±ya inebilir (overfit).

C Ã§ok kÃ¼Ã§Ã¼kse: Model biraz hata kabul eder, sÄ±nÄ±r yumuÅŸar (underfit riski).

ğŸ” Ä°pucu:
Modelin baÅŸarÄ±sÄ±nÄ±, gÃ¶rselliÄŸini ve genelleme yeteneÄŸini en iyi bu parametrelerle oynayarak gÃ¶rebilirsin.

8ï¸âƒ£ SonuÃ§
SVM ile Iris veri setinde Ã§ok yÃ¼ksek baÅŸarÄ± elde ediliyor.

Parametrelerle oynayarak modelin karar sÄ±nÄ±rlarÄ±nÄ± ve performansÄ±nÄ± doÄŸrudan gÃ¶zlemleyebiliyorsun.

GÃ¶rsel Ã§Ä±ktÄ±lar ile â€œhangi veri nerede, model nasÄ±l karar veriyor?â€ her ÅŸey aÃ§Ä±kÃ§a anlaÅŸÄ±lÄ±yor.

